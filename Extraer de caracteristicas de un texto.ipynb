{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq\n",
        "!pip install langchain-community\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"mi KEY\"\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "import json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eJqaL-1ieZc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "1MHiFzhXoDk0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializamos el modelo"
      ],
      "metadata": {
        "id": "bXS2YpMjaCLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Groq LLM\n",
        "llm = ChatGroq(\n",
        "    model_name=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "JysKioHQaB-s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define qué información quieres extraer"
      ],
      "metadata": {
        "id": "CQOjytMgYXqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creamos un clase Persona que sera la que defina cuales son los campos que el LLM va a estraer"
      ],
      "metadata": {
        "id": "VDXTQuBkYfgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field( #es un campo string Opcional por lo cual el si no exite puede asignarce un None por ej\n",
        "        default=None, description=\"The name of the person\"\n",
        "    )\n",
        "    lastname: Optional[str] = Field(\n",
        "        default=None, description=\"The lastname of the person if known\"\n",
        "    )\n",
        "    country: Optional[str] = Field(\n",
        "        default=None, description=\"The country of the person if known\"\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xiDMRyqUoIzB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definimos el extractor de datos"
      ],
      "metadata": {
        "id": "hLKoDMveaKtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una solicitud personalizada para proporcionar instrucciones y contexto adicional.\n",
        "# 1) Puedes añadir ejemplos a la plantilla de solicitud para mejorar la calidad de la extracción.\n",
        "# 2) Puedes introducir parámetros adicionales para tener en cuenta el contexto (por ejemplo, incluir metadatos sobre el documento del que se extrajo el texto).\n",
        "\n",
        "\n",
        "# Define a custom prompt to provide instructions and any additional context.\n",
        "# 1) You can add examples into the prompt template to improve extraction quality\n",
        "# 2) You can introduce additional parameters to take context into account (e.g., include metadata\n",
        "#    about the document from which the text was extracted.)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm. \"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"If you do not know the value of an attribute asked to extract, \"\n",
        "            \"return null for the attribute's value.\",\n",
        "        ),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "S8eQ8_V7Ss2R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm.with_structured_output(schema=Person)"
      ],
      "metadata": {
        "id": "nFRoddMdJthK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment = \"I absolutely love this product! It's been a game-changer for my daily routine. The quality is top-notch and the customer service is outstanding. I've recommended it to all my friends and family. - Sarah Johnson, USA\"\n",
        "chain.invoke({\"text\": comment})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUX5Z_D-c0qQ",
        "outputId": "546a3589-2b81-4580-cba6-f96c8c04872f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Person(name='Sarah Johnson', lastname='Johnson', country='USA')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción de una lista de entidades en lugar de una sola entidad"
      ],
      "metadata": {
        "id": "zbU1RjtDglmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "class Data(BaseModel):\n",
        "    \"\"\"Extracted data about people.\"\"\"\n",
        "\n",
        "    # Creates a model so that we can extract multiple entities.\n",
        "    people: List[Person]"
      ],
      "metadata": {
        "id": "OYyrSH10gnTl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GGGFn8UIg9Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input text that mentions multiple people\n",
        "text_input = \"\"\"\n",
        "Alice Johnson from Canada recently reviewed a book she loved. Meanwhile, Bob Smith from the USA shared his insights on the same book in a different review. Both reviews were very insightful.\n",
        "\"\"\"\n",
        "#nueva chain agregamos with_structured_outout\n",
        "chain = prompt | llm.with_structured_output(schema=Data)\n",
        "\n",
        "# Invoke the processing chain on the text\n",
        "response = chain.invoke({\"text\": text_input})\n",
        "\n",
        "# Output the extracted data\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiOmBSJJg9Sc",
        "outputId": "ccf5b401-b648-4c04-a92c-41d2ecc91c0c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(people=[Person(name='Alice Johnson', lastname='Johnson', country='Canada'), Person(name='Bob Smith', lastname='Smith', country='USA')])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sq2q8P_3cwj2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}